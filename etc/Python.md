# Python

* Generator
* 클래스를 상속했을때 메서드 실행 방식
* GIL 과 그로인한 성능 문제
* GC 작동 방식
* Celery
* PyPy 가 Cpython 보다 빠른 이유
* 메모리 누수가 발생할수 있는 경우
* Duck Typing



## Generator

Generator는 제네레이터 함수가 호출될때 반환되는 iterator(이터레이터) 의 일종이다. 제네레이터 함수는 일반적인 함수와 비슷하게 생겼지만 `yield 구문`을 사용해 데이터를 원하는 시점에 반환하고 처리를 다시 시작할수 있다. 일반적인 함수는 진입점이 하나라면 제네레이터는 진입점이 여러개라고 생각할수 있다. 이러한 특성 때문에 제너레이터를 사용하면 원하는 시점에 원하는 데이터를 받을수 있게 된다.

```python
>>> def generator():
...     yield 'hello'
...     yield 'world'
...     yield 'roche'
...
>>> gen = generator()
>>> next(gen)
'hello'
>>> next(gen)
'world'
>>> next(gen)
'roche'
>>> next(gen)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration
```

**동작**

1. yield 문이 포함된 제네레이터 함수를 실행하면 제네레이터 객체가 반환되는데 이 때는 함수의 내용이 실행되지 않는다.
2. `next()` 라는 빌트인 메서드를 통해 제네레이터를 실행시킬수 있으며 `next()` 메서드 내부적으로 iterator를 인자로 받아 이터레이터의 `__next__()` 메서드를 실행시킨다.
3. 처음 `__next__()` 메서드를 호출하면 함수의 내용을 실행하다 yield문을 만났을때 처리를 중단한다.
4. 이때 모든 local state는 유지되는데 변수의 상태, 명령어 포인터, 내부 스택, 예외 처리 상태를 포함한다.
5. 그 후 제어권을 상위 컨텍스트로 양보(yield) 하고 또 `__next__()` 가 호출되면 제네레이터는 중단된 시점부터 다시 시작한다.

> yield 문의 값은 어떤 메서드를 통해 제네레이터가 다시 동작했는지에 따라 다른데, `__next__() `를 사용하면 None 이고 `send()` 를 사용하면 메서드로 전달된 값을 갖게 되어 외부에서 데이터를 입력받을수 있게 된다.



**이점**

List, Set, Dict 표현식은 iterable(이터러블)하기에 for 표현식 등에서 유용하게 쓰일수 있다. 이터러블 객체는 유용한 한편 모든 값을 메모리에 담고 있어야 하기 때문에 큰 값을 다룰 때는 별로 좋지 않다. 제네레이터를 사용하면 yield를 통해 그때그때 필요한 값만을 받아 쓰기 때문에 모든 값을 메모리에 들고 있을 필요가 없게 된다.

> range() 함수는 python 2.x 에서 리스트를 반환하고 python 3.x 에서 range 객체를 반환한다. 이 range 객체는 제네레이터, 이터레이터가 아니다. 실제로 `next(range(1))` 를 호출해보면  `TypeError: 'range' object is not an iterator` 오류가 발생한다. 하지만 내부 구현상 제네레이터를 사용한것 처럼 메모리 사용에 있어 이점이 있다.

```python
>>> import sys
>>> a = [i for i in range(100000)]
>>> sys.getsizeof(a)
824464
>>> b = (i for i in range(100000))
>>> sys.getsizeof(b)
88
```

다만 제네레이터는 그때그때 필요한 값을 던져주고 기억하지는 않기 때문에 `a 리스트` 가 여러번 사용될수 있는 반면 `b 제네레이터` 는 한번 사용된후 소진된다. 이는 모든 이터레이터가 마찬가지인데 List, Set 은 이터러블 하지만 이터레이터는 아니기에 소진되지 않는다

```python
>>> len(list(a))
100000
>>> len(list(a))
0
```

또한 `while True` 구문으로 제공받을 데이터가 무한하거나, 모든 값을 한번에 계산하기엔 시간이 많이 소요되어 그때 그때 필요한 만큼만 받아 계산하고 싶을때 제네레이터를 활용할수 있다.



**Generator, Iterator, Iterable 간 관계**



![image-20201006170023370](https://camo.githubusercontent.com/b153d7a5035bf0f987050210c39b07af8caa2086/687474703a2f2f6e7669652e636f6d2f696d672f72656c6174696f6e73686970732e706e67)



**클래스를 상속했을때 메서드 실행방식**

인스턴스의 메서드를 실핸한다고 가정할때 `__getattribute__()`로 bound 된 method 를 가져온후 메서드를 실행한다. 메서드를 가져오는 순서는 `__mro__`에 따른다. MRO(method resolution order)는 메소드를 확인하는 순서로 파이썬 2.3 이후 C3 알고리즘이 도입되어 지금까지 사용되고 있다. 단일상속 혹은 다중상속일때 어떤 순서로 메서드에 접근할지는 해당 클래스의 `__mro__` 에 저장되는데 왼쪽에 있을수록 우선순위가 높다. B,C 를 다중상속 받은 D 클래스가 있고, B와 C는 각각 A를 상속받았을때 (다이아몬드 상속) D의 mro를 조회하면 볼수 있듯이 부모클래스는 반드시 자식클래스 이후에 위치해 있다. 최상위 object 클래스까지 확인했는데도 적절한 메서드가 없으면 `AttributeError` 를 발생시킨다.

```python
class A:
    pass

class B(A):
    pass

class C(A):
    pass

class D(B, C):
    pass

>>> D.__mro__
(__main__.D, __main__.B, __main__.C, __main__.A, object)
```



![image-20201006170344534](https://camo.githubusercontent.com/0e6265cbe9e6446e10bb1d3c6effe897f9ec5c84/68747470733a2f2f6d616b696e612d636f727075732e636f6d2f626c6f672f6d65746965722f323031342f707974686f6e2d6d726f2d636f6e666c696374)

python 2.3 이후 위 이미지와 같은 상속을 시도하려면 `TypeError: Cannot create a consistent method resolution` 오류가 발생한다.



## GIL과 그로인한 성능 문제

GIL 때문에 성능 문제가 대두되는 경우는 압축,정렬,인코딩 등 수행시간에 CPU의 영향이 큰 작업(CPU bound) 을 멀티 스레드로 수행하도록 한 경우이다. 이땐 GIL 때문에 멀티 스레드로 작업을 수행해도 싱글 스레드일때와 별반 차이가 나지 않는다. 이를 해결하기 위해선 멀티 스레드는 파일, 네트워크 IO 같은 IO bound 프로그램에 사용하고 멀티 프로세스를 활용해야 한다.



**GIL(Global interpreter Lock)**

GIL 은 스레드에서 사용되는 Lock을 인터프리터 레벨로 확장한 개념인데 여러 스레드가 동시에 실행되는걸 방지한다. 더 정확히 말하자면 어느 시점이든 하나의 Bytecode 만이 실행되도록 강제한다. 각 스레드는 다른 스레드에 의해 GIL이 해제되길 기다린 후에야 실행될수 있다. 즉 멀티 스레드로 만들었어도 본직적으로 싱글 스레드로 동작한다.

![image-20201006170650048](https://camo.githubusercontent.com/1fe774ef232b62985f46ecd543e6f81dd0962635/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313630302f312a6871575845516d794d5a43477a4141787264304e30672e706e67)

## GIL의 장점

코어 개수는 점점 늘어만 가는데 이 GIL 때문에 그 장점을 제대로 살리지 못하기만 하는것 같으나 이 GIL로 인한 장점도 존재한다. GIL을 활용한 멀티 스레드가 그렇지 않은 멀티 스레드보다 구현이 쉬우며, 레퍼런스 카운팅을 사용하는 메모리 관리 방식에서 GIL 덕분에 오버헤드가 적어 싱글 스레드일때 `fine grained lock 방식` 보다 성능이 우월하다. 또한 C extension 을 활용할때 GIL은 해제되므로 C library를 사용하는 CPU bound 프로그램을 멀티 스레드로 실행하는 경우 더 빠를수 있다.

> fine grained lock : 여러 개의 critical section을 묶어 lock을 걸어 제한한다.



## GC 작동 방식

파이썬에서 기본적으로 grabage collection(가비지 컬렉션) 과 regerence counting(레퍼런스 카운팅)을 통해 할당된 메모리를 관리한다. 기본적으로 참조 횟수가 0이 된 객체를 메모리에서 해제하는 레퍼런스 카운팅 방식을 사용하지만, 참조 횟수가 0은 아니지만 도달할수 없는 상태인 regerence cycle(순환 참조)가 발생했을 때는 가비지 컬렉션으로 그 상황을 해결한다.

> 레퍼런스 카운팅 방식을 통해 객체를 메모리에서 해제하는 행위가 가비지 컬렉션의 한 형태지만 여기서는 순환 참조가 발생했을 때 cyclic garbage collector 를 통한 **가비지 컬렉션** 과 **레퍼런스 카운팅**을 통한 가비지 컬렉션을 구분했다.

**레퍼런스 카운팅**

모든 객체는 참조당할때 레퍼런스 카운터를 증가시키고 참조가 없어질 때 카운터를 감소시킨다. 이 카운터가 0이 되면 객체가 메모리에서 해제한다. 어떤 객체의 레퍼런스 카운트를 보고 싶다면 `sys.getrefcount()` 로 확인할수 있다.



**순환 참조**

순환 참조의 간단한 예제는 자기 자신을 참조하는 객체다.

```python
>>> l = []
>>> l.append(l)
>>> del l
```

`l`의 참조 횟수는 1 이지만 이 객체는 더이상 접근할수 없으며 레퍼런스 카운팅 방식으로는 메모리에서 해제될수 없다.

또 다른 예로는 서로 참조하는 객체다.

```python
>>> a = Foo()  # 0x60
>>> b = Foo()  # 0xa8
>>> a.x = b  # 0x60의 x는 0xa8를 가리킨다.
>>> b.x = a  # 0xa8의 x는 0x60를 가리킨다.
# 이 시점에서 0x60의 레퍼런스 카운터는 a와 b.x로 2
# 0xa8의 레퍼런스 카운터는 b와 a.x로 2다.
>>> del a  # 0x60은 1로 감소한다. 0xa8은 b와 0x60.x로 2다.
>>> del b  # 0xa8도 1로 감소한다.
```

이 상태에서 `0x60.x`와 `0xa8.x`가 서로를 참조하고 있기 때문에 레퍼런스 카운트는 둘 다 1 이지만 도달할 수 없는 가비지가 된다.

**가비지 컬렉터**

파이썬의 `gc` 모듈을 통해 가비지 컬렉터를 직접 제어할수 있다. `gc` 모듈은 cyclic garbage collection 을 지원하는데 이를 통해 reference cycles(순환 참조)를 해결할 수 있다. gc 모듈은 오로지 순환 참조를 탐지하고 해결하기위해 존재한다. 



**가비지 컬렉션의 작동 방식**

순환 참조 상태도 해결할수 있는 cyclic garbage collection 이 어떤 방식으로 동작하는지는 결국 **어떤 기준으로 가비지 컬렉션이 발생**하고 **어떻게 순환 참조를 감지**하는 지에 관한 내용이다. 

**어떤 기준으로 가비지 컬렉션이 일어나는가**

앞에서 제기했던 의문은 결국 발생 기준에 관한 의문이다. 가비지 컬렉터는 내부적으로 `generation`(세대) 과 `threshold`(임계값)로 가비지 컬렉션 주기와 객체를 관리한다.



**Celery**

`Celery`는 메시지 패싱 방식의 분산 비동기 작업 큐이다. 작업(Task)은 브로커(Broker)를 통해 메시지로 워커에 전달되어 처리된다. 작업은 멀티프로세싱, eventlet, gevent를 사용해 하나 혹은 그 이상의 워커에서 동시적으로 실행되며 백그라운드에서 비동기적으로 실행될수 있다.

* [celery를 통한 pdf 생성 및 다운](https://spoqa.github.io/2012/05/29/distribute-task-with-celery.html)



## PyPy가 CPython 보다 빠른 이유

CPython 은 일반적인 인터프리터인데 반해 PyPy는 실행 추적 JIT(Just In Time) 컴파일을 제공하는 인터프리터기 때문이다. PyPy 는 RPython 으로 컴파일된 인터프리터 인데, C로 작성된 RPython 툴체인으로 인터프리터 소스에 JIT 컴파일을 위한 힌트를 추가해 CPython 보다 빠른 실행 속도를 가질수 있다

**PyPy**

PyPy 는 파이썬으로 만들어진 파이썬 인터프리터다. 일반적으로 파이썬 인터프리터를 다시 한번 파이썬으로 구현한 것이기에 속도가 매우 느릴거라 생각하지만 실제로 PyPy는 Cpython 보다 빠르다.

**실행 추적 JIT 컴파일**

메소드 단위로 최적화 하는 전통적인 JIT과 다르게 런타임에서 자주 실행되는 루프를 최적화 한다.

**RPython(Restricted Python)**

**RPython** 은 이런 실행 추적 JIT 컴파일을 C로 구현해 툴체인을 포함한다. 그래서 RPython 으로 인터프리터를 작성하고 툴체인으로 힌트를 추가하면 인터프리터에 실행추적 JIT 컴파일러를 빌드한다. 참고로 RPython 은 PyPy 프로젝트 팀이 만든 일종의 인터프리터 제작 프레임워크(언어)다. 동적언어인 Python 에서 표준 라이브러리와 문법에 제약을 가해 변수의 정적 컴파일이 가능하도록 RPython을 만들었으며, 동적언어 인터프리터를 구현하는데 사용된다.

언어사양(파이썬 언어 규칙, BF 언어 규칙등) 과 구현(실제 인터프리터 제작)을 분리함으로써 어떤 동적 언어에 대해서라도 자동으로 JIT컴파일러를 생성할수 있게 되었다.

